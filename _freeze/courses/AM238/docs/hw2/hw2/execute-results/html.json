{
  "hash": "cb4690d5877a0b81acb1085005bfd6f4",
  "result": {
    "engine": "julia",
    "markdown": "---\ntitle: Homework 2\ndate: 2024-10-14\nauthor:\n  - name: Kevin Silberberg\n    id: ks\n    orcid: 0009-0009-4825-1865\n    email: ksilberb@ucsc.edu\n    affiliation:\n      - name: University of California Santa Cruz\n        city: Santa Cruz\n        state: CA\n        href: www.ucsc.edu\nengine: julia-1.11\njulia:\n  exeflags: [\"--project=/home/kevinsilberberg/Repos/paxnomada/courses/AM238/\"]\nexecute:\n  daemon: true\n  cache: true\n  eval: true\n  freeze: auto\n---\n\n# Question 1\n\n## Problem definition\n\nConsider the random variable:\n\\begin{align}\nY = \\sum_{j = 1}^{n}b_jX_j\n\\end{align}\n\nwhere at least one $b_j$ is non-zero, and $(X_1, ..., X_n)$ are jointly Gaussian random variables with mean $\\mathbf{\\mu} = (\\mu_1, ..., \\mu_{n})$ and convergence matrix $\\mathbf{\\Sigma}$.\n\n## Part A\n\n#### Show that $Y$ is a Gaussian random variable.\n\nThe characteristic function of a jointly Gaussian random variable:\n<div style=\"font-size: 120%;\">\n\\begin{align}\n\\phi_X(t) = e^{it^T\\mu - \\frac{1}{2} t^T\\Sigma t}\n\\end{align}</div>\n\nLet $\\mathbf{B} = \\left[b_1, b_2, ..., b_n\\right]^T$ such that $Y = \\mathbf{B^T X} = b_1x_1 + b_2x_2 + ... + b_nx_n$.\n\nLet us find the characteristic function of $Y$:\n<div style=\"font-size: 120%;\">\n\\begin{align}\n\t\\phi_Y(t) &= \\mathbb{E}\\left[e^{it \\sum_{j=1}^{n}b_j X_j}\\right]\\\\\n\t&= \\phi_X(tb_1, tb_2, ..., tb_n) \\\\\n\t&= e^{it\\left(B^T \\mu\\right) - \\frac{1}{2} t^2 \\left(B^T \\Sigma B\\right)}\n\\end{align}</div>\n\nThus $Y$ is a normally distributed Gaussian random variable via its characteristic function.\n\n## Part B\n\n#### Compute the mean and variance of $Y$ as a function of $\\{b_j\\}$, $\\mathbf{\\mu}$ and $\\mathbf{\\Sigma}$\n\nFrom the characteristic function in part A, we can see that the mean and variance of $Y$ is given as:\n\n\\begin{align}\n\t\\mathbb{E}\\left[Y\\right] &= B^T \\mu \\\\\n\t\\ \\\\\n\t\\mathbb{E}\\left[Y^2\\right] - \\mathbb{E}\\left[Y\\right]^2 &= B^T \\Sigma B\n\\end{align}\n\n\n# Question 2\n\n## Problem definition\n\nConsider the two-dimensional random vector $\\mathbf{X} = \\left[X_1, X_2\\right]$ with joint PDF\n\n$$\tp(x_1, x_2) =\n\t\\begin{cases}\n\t\tK\\cos^2{(10x_1x_2)} & (x_1, x_2) \\in \\left[0, 1\\right] \\times \\left[0,1\\right] \\\\\n\t\t0 & \\text{otherwise}\n\t\\end{cases}$${#eq-probtwo}\n\nwhere\n\n\\begin{align}\n\tK = \\frac{40}{Si(20) + 20} \\quad , \\quad Si(x) = \\int_{0}^{x} \\frac{\\sin{(t)}}{t} dt\n\\end{align}\n\n## Part A\n\n#### Compute the conditional PDFs $p(x_1 | x_2)$ and $p(x_2 | x_1)$.\n\nLet us compute the conditional probability of $p(x_1|x_2)$\n\n\\begin{align}\n\tp(x_1 | x_2) &= \\frac{p(x_1, x_2)}{p(x_2)} \\\\\n\t&= \\frac{p(x_1, x_2)}{\\int_{-\\infty}^{\\infty} p(x_1, x_2) dx_1} \\\\\n\t&= \\frac{K\\cos^2{(10x_1x_2)}}{K\\int_{0}^{1} \\cos^2{(10x_1x_2)} dx_1} \\\\\n\t&= \\frac{K\\cos^2{(10x_1x_2)}}{\\frac{K}{10x_2}\\int_{0}^{10x_2}\\cos^2{(u)}du} \\\\\n\t&= \\frac{K\\cos^2{(10x_1x_2)}}{\\frac{K}{10x_2}\\left[\\frac{1}{2}\\left(u + \\sin{(u)}\\cos{(u)}\\right)\\right]_{0}^{10x_2}}\\\\\n\t&= \\frac{K\\cos^2{(10x_1x_2)}}{\\frac{K}{40x_2}\\left(2u + \\sin{(2u)}\\right)\\bigg{|}_{0}^{10x_2}} \\\\\n\t&= \\frac{40x_2\\cos^2{(10x_1x_2)}}{20x_2 + \\sin{(20x_2)}}\n\\end{align}\n\nBy taking the integral with respect to $x_2$ we have that $$p(x_1) = K\\left(\\frac{\\sin{(20x_1)}}{40x_1} + \\frac{1}{2}\\right)$$\n\nthus the conditional probabilities are:\n\\begin{align}\n\tp(x_1 | x_2) &= \\frac{40x_2\\cos^2{(10x_1x_2)}}{20x_2 + \\sin{(20x_2)}} \\\\\n\t\\ \\\\\n\tp(x_2 | x_1) &= \\frac{40x_1\\cos^2{(10x_1x_2)}}{20x_1 + \\sin{(20x_1)}}\n\\end{align}\n\n## Part B\n\n#### Write a computer code that samples the PDF of (@eq-probtwo) using the gibbs sampling algorithm. Plot the PDF and the samples you obtain from the Gibbs algorithm on a 2d contour plot, similarly to Figure 3 in the course note 2.\n\n::: {#2 .cell execution_count=1}\n``` {.julia .cell-code}\nusing GLMakie\nusing QuadGK\n\n# cumulative trapazoidal rule\nfunction cumsumtrap(f::Function, x)\n    y = f.(x)\n    N = length(x)\n    x1 = @view x[1:N-1]\n    x2 = @view x[2:N]\n    y1 = @view y[1:N-1]\n    y2 = @view y[2:N]\n    integral = cumsum(((x2.-x1).*(y1.+y2))./2.0)\n    integral ./= integral[end]\n    return [0; integral]\nend\n\n# CDF inverse sampler\nfunction sampleInverseCDF(x::Float64, points::Matrix{Float64})\n    idx = findfirst(points[:, 1] .> x)\n    if idx === nothing\n        p1 = points[end-1, :]\n        p2 = points[end, :]\n    elseif idx == 1\n        p1 = points[1, :]\n        p2 = points[2, :]\n    else\n        p1 = points[idx-1, :]\n        p2 = points[idx, :]\n    end\n    liy(x, p1, p2)\nend\n\n# Linear Interpolator\nfunction liy(x::Float64, p1::Vector{Float64}, p2::Vector{Float64})\n    x1, y1 = p1\n    x2, y2 = p2\n    if isapprox(x1, x2, atol = 1e-12)\n        return (y1 + y2) / 2.0\n    end\n    return y1 + (x - x1)*(y2 - y1)/(x2 - x1)\nend\n\n# Sine Integral\nfunction Si(x::Float64)\n    return x == 0.0 ? 0.0 : quadgk(t -> sin(t)/t, 0.0, x, rtol=1e-3)[1]\nend\n\n# joint PDF for problem 2 p(x, y)\nfunction p(x::Float64, y::Float64)\n    if x < 0.0 || y < 0.0\n        return 0.0\n    end\n    return ((40.0)/(Si(20.0) + 20.0))*cos(10.0*x*y)*cos(10.0*x*y)\nend\n\n# Conditional PDF p(x | y)\nfunction pxGy(x::Float64, y::Float64)\n    denom = (20.0*y+sin(20.0*y))\n    if abs(denom) < 1e-6\n        return 0.0\n    end\n    return (40.0*y*cos(10.0*x*y)*cos(10.0*x*y))/denom\nend\n\n# Conditional PDF p(y | x)\nfunction pyGx(x::Float64, y::Float64)\n    denom = (20.0*x+sin(20.0*x))\n    if abs(denom) < 1e-6\n        return 0.0\n    end\n    return (40.0*x*cos(10.0*x*y)*cos(10.0*x*y))/denom\nend\n\n# Mesh of the surface of the joint PDF\nfunction getSurface()\n    xs = LinRange(0, 1, 100)\n    ys = LinRange(0, 1, 100)\n    zs = [p(x, y) for x in xs, y in ys]\n    return xs, ys, zs\nend\n\n# gibbs sampler\nfunction gibbsSample(N::Integer)\n    samples = Matrix{Float64}(undef, N, 2)\n    r = LinRange(0.0, 1.0, 1000)\n    # initialize random x1\n    y0 = rand()\n    samples[1, 1] = sampleInverseCDF(rand(), hcat(cumsumtrap(x -> pxGy(x, y0), r), r))\n    for i=2:N\n        samples[i-1, 2] = sampleInverseCDF(rand(), hcat(cumsumtrap(y -> pyGx(samples[i-1, 1], y), r), r))\n        samples[i, 1] = sampleInverseCDF(rand(), hcat(cumsumtrap(x -> pxGy(x, samples[i-1, 2]), r), r))\n    end\n    samples\nend\n\n# Part B problem solution\nfunction partb(N::Integer)\n    fig = Figure()\n    ax = Axis(fig[1,1])\n    xs, ys, zs = getSurface()\n    co = contourf!(ax, xs, ys, zs,\n                   extendlow = :auto,\n                   extendhigh = :auto)\n    samples = gibbsSample(N)\n    scatter!(ax, samples[:, 1], samples[:, 2], markersize = 3, color = :red)\n    Colorbar(fig[1, 2], co)\n    save(\"q2partb.png\", fig)\nend\npartb(5000);\n```\n:::\n\n\n![Plot of 5000 samples from the joint PDF using Gibbs sampling](q2partb.png){fig-align=\"center\"\nwidth=\"100%\"}\n\n## Part C\n\nWrite a program to calculate the sample mean and sample standard deviation of the random function\n\n$$f(y;X_1, X_2) = \\sin{(4 \\pi X_1 y)} + \\cos{(4 \\pi X_2 y)} \\quad y \\in [0,1]$${#eq-partc}\n\nwhere $X_1$ and $X_2$ are random variables with joint PDF given by (@eq-probtwo).\n\n::: {#4 .cell execution_count=1}\n``` {.julia .cell-code}\nfunction f(y::Float64, X1::Float64, X2::Float64)\n    return sin(4*π*X1*y) + cos(4*π*X2*y)\nend\n\nfunction partc()\n    N = Int64(5e4)\n    M = Int64(500)\n    r = LinRange(0.0, 1.0, M)\n    fig = Figure()\n    grid = fig[1, 1] = GridLayout()\n    ax = Axis(grid[1, 1],\n              title = \"y by sample mean and standard deviation\",\n              xlabel = \"y\")\n    samples = Matrix{Float64}(undef, N, M)\n    for i=1:N\n        X1, X2 = gibbsSample(2)[:, 1]\n        for j=1:M\n            samples[i, j] = f(r[j], X1, X2)\n        end\n    end\n    μᵢ = vec(sum(j -> j, samples, dims=1) ./ N)\n    μₜ = sum(μᵢ) / M\n    σᵢ = vec(sqrt.(sum((samples .- μᵢ') .^ 2, dims = 1) ./ (N - 1)))\n    means = lines!(ax, r, μᵢ, color = :red)\n    stdv = lines!(ax, r, σᵢ, color = :blue)\n    Legend(fig[1, 2], [means, stdv], [\"mean\", \"std dev\"])\n    save(\"q2partc.png\", fig)\nend\npartc();\n```\n:::\n\n\n![Plot of the mean and standard deviation for 50000 samples on a 500 spatial grid of evenly distributed values of y from 0 to 1](q2partc.png){fig-align=\"center\"\nwidth=\"100%\"}\n\n# Question 3\n\n## Problem definition\n\n#### Write a computer code that estimates the PDF of the random variable\n\n$$\\bar{X}_N = \\frac{X_1 + ... + X_N}{N} \\quad \\text{sample mean}$${#eq-probthree}\n\nwhere $\\{X_j\\}$ are independent identically distributed Cauchy random variables with PDF\n\n\\begin{equation}\n\tp_{X_j}(x) = \\frac{1}{\\pi (1 + x^2)} \\quad j = 1, ..., N\n\\end{equation}\n\nusing the inverse CDF function and relative frequency approach you developed in HW1.\n\nPlot your results for $N = 10^3$ and $N = 10^5$.\n\n## Solution\n\nLet us find the inverse cdf of the cauchy distribution:\n\n\\begin{align}\n\tF(x) = \\frac{1}{\\pi} \\int_{-\\infty}{x}\\frac{1}{(1 + y^2)}dy &= \\frac{1}{\\pi}\\left[\\arctan{(y)}\\bigg{|}_{-\\infty}^x\\right] \\\\\n\t&= \\frac{1}{\\pi}\\left[\\arctan{(x)} - \\arctan{(-\\infty)}\\right] \\\\\n\\end{align}\n\n\\begin{align}\n\tF^{-1}(x) = \\tan{(\\pi(x - \\frac{1}{2}))}\n\\end{align}\n\n::: {#6 .cell execution_count=1}\n``` {.julia .cell-code}\nusing KernelDensity\nfunction PDF(x::Float64)\n    return 1.0 / (π*(1+x^2))\nend\n\nfunction inverseCDF(x::Float64)\n    return tan(π*(x - 0.5))\nend\n\nfunction question3(N::Integer)\n    samples = Vector{Float64}(undef, 1000)\n    for j in eachindex(samples)\n        s = Vector{Float64}(undef, N)\n        for i in eachindex(s)\n            s[i] = inverseCDF(rand())\n        end\n        samples[j] = sum(s) / Float64(lastindex(s))\n    end\n\n    fig = Figure()\n    ax = Axis(fig[1, 1])\n    k = kde(samples)\n    r = LinRange(-10.0, 10.0, 1000)\n    lines!(ax, r, PDF.(r), color = :orange, label = \"PDF\")\n    lines!(ax, k.x, k.density, color = :red, label = \"KDE N=$N\", linestyle = :dash)\n    xlims!(ax, -10, 10)\n    fig[1, 2] = Legend(fig, ax, \"Legend\", framevisible = false)\n    save(\"question3_$(N).png\", fig)\nend\nquestion3(1000);\nquestion3(100000);\n```\n:::\n\n\n![Kernel Density estimate of the PDF of the random variable $\\bar{X}_N$ from 1000 samples with N = 1000](question3_1000.png){fig-align=\"center\"\nwidth=\"100%\"}\n\n![Kernel Density estimate of the PDF of the random variable $\\bar{X}_N$ from 1000 samples with N = 100000](question3_100000.png){fig-align=\"center\"\nwidth=\"100%\"}\n\n",
    "supporting": [
      "hw2_files"
    ],
    "filters": [],
    "includes": {}
  }
}